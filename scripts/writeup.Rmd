---
title: "Act for Peace Interview: Data Analysis and Write-up"
author: "Charith Wijewardena"
output: 
  html_document: 
    toc: yes
    toc_depth: 4
toc-title: "Contents"
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE, out.width = "90%", fig.align = "center")
```

```{r}
library(dplyr)
library(forcats)
library(stringr)
library(tidyr)
library(ggplot2)
library(scales)
library(showtext)
library(ggthemes)
library(tidytext)

load("C:/Users/chari/Documents/afp-data/clean_data.Rda")
load("C:/Users/chari/Documents/afp-data/raw_data.Rda")
load("C:/Users/chari/Documents/afp-data/modelling_data.Rda")
```

```{r cache=TRUE}
font_add_google("Open Sans", family = "Open Sans Semibold", regular.wt = 600)
font_add_google("IBM Plex Sans")
font_add_google("IBM Plex Mono")
```

```{r}
showtext_auto()

ret <- theme_minimal() +
      theme(
        plot.title = element_text(family = "Open Sans Semibold", size = 20),
        plot.subtitle = element_text(family = "IBM Plex Sans", size = 18),
        plot.caption = element_text(family = "IBM Plex Mono", size = 16, colour = "grey50", hjust = 0.5),
        axis.title = element_text(family = "IBM Plex Sans", size = 18),
        axis.text = element_text(family = "IBM Plex Mono", size = 16.5),
        legend.title = element_text(family = "Open Sans Semibold", size = 14),
        legend.text = element_text(family = "IBM Sans Plex", size = 14),
        panel.grid.major.x = element_line(colour = "white", linetype = "dashed"),
        panel.grid.minor.x = element_line(colour = "white", linetype = "dashed"),
        panel.grid.major.y = element_line(colour = "grey75", linetype = 2, size = 0.3),
        panel.grid.minor.y = element_line(colour = "grey75", linetype = 2, size = 0.3)
      )

theme_set(ret)
```

----

## Introduction

### Managing expectations

Before I begin, please allow me to lay the boundaries of this analysis. 

Given that the purpose of this task is simply to gain some insight into my thought process, methodology and personality, I'm going to take on a narrative style in this write-up and guide you through my thought process as I explored the data. There are many paths that I could have gone down in trying to answer the questions presented. The approach that I took was to simply pick one of those after doing some exploratory data analysis and seeing where that led. In real life, this would have been an iterative process of exploration and evaluation. The questions we orignally asked may have even evolved based on our findings. 

However, I decided not to iterate on my findings or modelling outcomes regardless of model accuracy. Given the motivation of this task as well as the limited time available, this seemed reasonable.

Anyway, I like to explain things so I hope you find this enjoyable at the very least! Who knows, perhaps you'll even learn something new!! `r emo::ji("sparkles")`

### Setting up computation

All computation was performed in R using R version 4.1.2. You can access all my code via Github [here](https://github.com/chaz23/afp-interview). Throughout this document I will add links to scripts that I wrote for each section if relevant. I also used the **renv** package to produce as reproducible an environment as possible. 

`r emo::ji("bulb")` ***renv** manages all the packages and their versions that I have used for this project. If you were to clone my repo and run my code, the renv lockfile would ensure that you used the same R and package versions that I did.* 

However, as I have kept all input and output data on my local machine in the interests of confidentiality (i.e not storing it in a Github public repository), this is mostly for illustrative purposes as far as this write-up goes. In real life, I like to maintain reproducibility.

### Why are we here and what's coming next?

Analysis without a motivation is often aimless, so I'm glad that you have provided some questions to keep us on track!

* How these individuals might be segmented and why?
* How would the donation ask in their next communication be calculated and why?
* What might you send to the groups you identify and what might you not send to them and why?
* How would you improve on these things in the future?

To keep my data analysis as methodical as I can here, I've tried to divide my workflow into 3 stages. (It's usually an iterative process but remember I said I'm not iterating here). The 3 stages are:

* **Validation:** Evaluating data cleanliness and self-consistency, handling missing data and outliers etc.
* **Description and modelling:** Looking at distributions, correlations etc. Articulating objective interpretations of the data that we can all agree on, and then modelling based on those.
* **Evaluation:** Given the descriptions and modelling, **how do we answer our original questions?** 

Cool, now I'll get straight into it.

----

## Introducing ourselves to the data

### Towards internal consistency

Before working with the data directly, I take some time to check its level of cleanliness and internal consistency. After all, garbage in equals garbage out. One thing I discovered early on is that the data between 2 tables - Contacts and Transactions - does not seem to match up. I'll remind you briefly what columns we had in the original data.

**Contacts:**

```{r}
contacts_raw %>% str()
```

**Transactions:**

```{r}
transactions_raw %>% str()
```

It appears that the sum of transactions for **7,592 out of 32,188 supporters** in the Transactions table (sum of the `Amount` column) was different to the value of `Total Gifts` for those same supporters in the Contacts table.

```{r}
contacts %>% 
  left_join((transactions %>% 
               group_by(supporter_id) %>% 
               summarise(amount = sum(amount))), 
            by = "supporter_id") %>% 
  filter(total_gifts < amount) %>% 
  select(supporter_id, total_gifts_from_contacts = total_gifts, total_amount_from_transactions = amount) %>% 
  
  mutate(diff = abs(total_gifts_from_contacts - total_amount_from_transactions)) %>% 
  filter(diff <= 10)
```

My initial hunch was that this could be a rounding error, for example where `r dollar(472)` in one table was recorded as `r dollar(470)` in another.

```{r}
contacts %>% 
  left_join((transactions %>% 
               group_by(supporter_id) %>% 
               summarise(amount = sum(amount))), 
            by = "supporter_id") %>% 
  filter(total_gifts < amount) %>% 
  select(supporter_id, total_gifts_from_contacts = total_gifts, total_amount_from_transactions = amount) %>% 
  mutate(diff = total_amount_from_transactions - total_gifts_from_contacts) %>% 
  ggplot(aes(diff)) +
  geom_histogram(color = "grey") +
  scale_x_log10(labels = dollar) +
  labs(title = "Discrepancy between Contacts and Transactions isn't a rounding error",
       subtitle = "Many transactions appear to be missing entirely from Contacts",
       x = "Difference in total gifts between Contacts and Transactions",
       y = "Number of supporters",
       caption = "FIGURE 1: Discrepancy between total gifts in Contacts and Transactions tables (on log scale)")
```

Given that about a quarter of the Transactions dataset is inconsistent with Contacts, this is a **huge red flag** and in real life I would have investigated this further to update my understanding and check whether I had made any other mistakes. However, it does seem that ~57% of the discrepancies are only off by $10 or less, so **perhaps it's a mix of rounding errors and something else**. 

For now I chose to ignore this fact and move on.

### Outliers, missing data and augmentation

I've created a "master" dataset by merging what I feel are the relevant parts of Transactions and Non-Financial Actions into Contacts, so I only have to work with one table. I want to get a sense of the overall distributions of my data, and understand **how much data is missing**.

`r emo::ji("bulb")` *Understanding the causes of missing data is especially important if we want to feed our data to a machine learning model, as the vast majority of them do not like missing values. In those cases, we would need to impute those values, drop them or figure out another way to handle the problem.* 

Some preparatory steps I took to clean the data are as follows:

* Renamed columns according to the [R style guide](https://style.tidyverse.org/syntax.html#syntax).
* Joined an [external postcodes dataset](https://gist.github.com/randomecho/5020859) to:
  * Get supporter mailing location (at the postcode level) in latitude and longitude.
  * Fill in missing values for the `state` column where the postcode was known. Note that this may yield slight inaccuracies in edge cases where multiple states share the same postcode.
* Cleaned the `state` column for consistency - eg: change N.S.W to NSW etc.
* Removed deceased supporters as they might confuse our model if we decide to use one later on to predict giving.
* Added a `nonfin_action` column to Contacts to indicate if a supporter has previously participated in any non-financial actions.
* Added average gift amounts for each of the time periods presented. (Eg: `avg_gift_amount_last_year`).
* Joined the Contacts and Transactions tables together to indicate what campaigns and source channels a supporter had participated in before. Having the campaigns and channels in this format means that I can possibly tokenize this data later if I want to feed it to a machine learning model. **I removed information related to 2017 to avoid data leakage**

`r emo::ji("bulb")` *Data leakage is when information from outside the training dataset is used to build a model. As you'll see later, I try to predict total donations in 2017 while pretending that I live in the year 2016 - if I used information from 2017, that would be an unfair and misleading advantage for my model.*

```{r}
contacts %>% 
  select(supporter_id, previous_campaigns) %>% 
  filter(previous_campaigns != "Unknown")
```

Furthermore, I took **"this year" to mean the calendar year 2017.**

This is what my new tidied dataset looks like, ready for analysis. Here I've split the variables by data type (character and numeric). What I'm usually interested in seeing is the completion rate, which tells me the fraction of missing values, the number of unique entries in the character variables and the histograms of the numeric variables. What stands out to me is how much missing information we have on supporters when it comes to age. This is a pity, as age could well be a good signal when it comes to predicting giving.

The histograms of the gift numbers and totals seem to indicate a log-normal distribution which we'll check later. Understandably, many people give small amounts, while a handful donate massively. There's a mix of demographic variables (gender, religion, age, location), attitudinal (communication preference) and behavioural (number of gifts given and average gift amount).

```{r}
contacts %>% skimr::skim() %>% skimr::partition()
```

----

## Diving deep with EDA

This is where I begin to build some plots to start getting a feel for the data. I'll show you a handful of the ones I found interesting.

### Demographics

`r emo::ji("warning")` *Bear in mind that 88% of the data was not included in the following graphs containing `age` as it was unknown. However, let's assume for now that the values for age that we have are uniformly sampled from the population.*

```{r}
contacts %>% 
  filter(!is.na(age)) %>% 
  mutate(age_bin = 5 * (age %/% 5),
         age_bin = factor(age_bin)) %>%
  ggplot(aes(age_bin, avg_gift_amount, fill = gender)) +
  geom_boxplot() +
  coord_cartesian(ylim = c(0, 250)) +
  labs(title = "Males appear to donate larger amounts and have a wider spread than females",
       x = "Age",
       y = "Average donation amount",
       fill = "Gender",
       caption = "FIGURE 2: Boxplot of average donation amount by age and gender") +
  theme(legend.position = "top")

contacts %>% 
  filter(total_gifts > 0) %>% 
  ggplot(aes(age, avg_gift_amount, color = gender)) +
  geom_point(position = "jitter", alpha = 0.2) +
  scale_y_log10(labels = dollar) +
  geom_smooth() +
  labs(title = "Another perspective: avg donation amount vs. age and gender",
       subtitle = "Beware: the fitted line only looks flat because the y-axis is log-transformed!",
       x = "Age",
       y = "Average donation amount",
       fill = "Gender",
       caption = "FIGURE 3: Scatterplot of average donation amount by age and gender") +
  theme(legend.position = "top")
```

To dig a bit further into this, I took `age`, log-transformed `avg_gift amount` and `num_gifts_last_365_days` and then did a pairwise correlation between them all. The values below are the correlation coefficients. The value 0.56 suggests that there is a moderately strong relationship between age and average gift amount. 

```{r}
contacts %>% 
  select(age, avg_gift_amount, num_gifts_last_365_days) %>% 
  mutate(avg_gift_amount = log10(avg_gift_amount + 0.1),
         num_gifts_last_365_days = log10(num_gifts_last_365_days + 0.1)) %>% 
  filter(!is.na(age)) %>% 
  corrr::correlate() %>% 
  corrr::fashion()
```

```{r}
contacts %>% 
  ggplot(aes(age, fill = gender)) +
  geom_histogram(binwidth = 2, color = "grey", position = "fill") +
  labs(title = "More females donate across all age groups than males",
       subtitle = "Do younger donors not like to disclose their gender?",
       x = "Age",
       y = "Proportion of supporters",
       fill = "Gender",
       caption = "FIGURE 4: Gender proportions of donors across age groups") +
  scale_y_continuous(labels = percent) +
  theme(legend.position = "top")

contacts %>% 
  ggplot(aes(age, fill = religion)) +
  geom_histogram(binwidth = 2, color = "grey") +
  labs(title = "Most older donors identify as Christian",
       x = "Age",
       y = "Number of supporters",
       fill = "Religion",
       caption = "FIGURE 5: Number of donors by age and religion") +
  theme(legend.position = "top")
```

```{r}
aus_map_data <- map_data("world") %>% 
  as_tibble() %>% 
  filter(region == "Australia") %>% 
  filter(long < 155)

contacts %>% 
  filter(country == "Australia") %>% 
  filter(lon > 112) %>%
  ggplot(aes(lon, lat)) +
  geom_polygon(aes(long, lat, group = group), data = aus_map_data, fill = "white", color = "grey") +
  geom_point(aes(color = state, size = avg_gift_amount), alpha = 0.2) +
  theme_map() +
  labs(title = "Most larger donors are populated around the major cities",
       x = "Age",
       y = "Number of supporters",
       fill = "State",
       size = "Avg Gift Amount",
       caption = "FIGURE 6: Donor locations around Australia") +
  theme(legend.position = "top",
        legend.text = element_text(family = "IBM Plex Mono", size = 16),
        legend.title = element_text(family = "IBM Plex Mono", size = 16),
        plot.title = element_text(family = "Open Sans Semibold", size = 20),
        plot.caption = element_text(family = "IBM Plex Mono", size = 16, colour = "grey50", hjust = 0.5))
```

```{r}
contacts %>% 
  filter(!is.na(state)) %>% 
  filter(country == "Australia") %>%
  ggplot(aes(total_gifts + 1, fill = state)) +
  geom_histogram(color = "grey", position = "fill") +
  scale_x_log10(labels = dollar) +
  scale_y_continuous(labels = percent) +
  labs(title = "The proportion of donors in each group increases for ACT",
       subtitle = "Do ACT donors generally donate more?",
       x = "Total amount donated",
       y = "Proportion of supporters",
       fill = "State",
       caption = "FIGURE 7: Proportion of donors in each donation bracket by state") +
  theme(legend.position = "top")

contacts %>% 
  filter(!is.na(age) & !is.na(state)) %>% 
  ggplot(aes(age, fill = state)) +
  geom_histogram(color = "grey", binwidth = 5, position = "fill") +
  scale_y_continuous(labels = percent) +
  labs(title = "Or could this increase be correlated with age?",
       subtitle = "Could we have an older ACT population in our donor base?",
       x = "Age",
       y = "Proportion of supporters",
       fill = "State",
       caption = "FIGURE 8: Proportion of donors in each age bracket by state") +
  theme(legend.position = "top")
```

Trying to correlate age vs. total gifts does show a moderately strong linear relationship. It makes sense - the longer you've lived, the more time you've had to donate! If this is true, we should watch out for this multicollinearity later on if we want to use these variables as predictors in a model. But it needs further looking into.

```{r}
contacts %>% 
  select(age, total_gifts) %>%
  mutate(total_gifts = log10(total_gifts + 0.1)) %>% 
  na.omit() %>% 
  corrr::correlate() %>% 
  corrr::fashion()
```

### Behaviours

```{r}
campaigns_summarised <- transactions %>%
  mutate(source = str_replace_all(source, "-", " "),
         source = str_replace_all(source, "[0-9]", " ")) %>% 
  unnest_tokens(campaign, source, to_lower = FALSE) %>% 
  left_join(campaign_list, by = "campaign") %>% 
  mutate(campaign = if_else(!is.na(desc), paste0(campaign, " (", desc, ")"), campaign)) %>% 
  group_by(campaign) %>% 
  summarise(n = n(),
            min_amount = min(amount),
            max_amount = max(amount),
            median_amount = median(amount),
            avg_amount = mean(amount),
            total_amount = sum(amount)) %>% 
  arrange(desc(n))

campaigns_summarised %>%
  mutate(campaign = fct_reorder(campaign, n)) %>% 
  head(20) %>% 
  ggplot(aes(n, campaign)) +
  geom_col() +
  labs(title = "Regular givers and Christmas Bowl are the highest volume campaigns",
       subtitle = "EOFY also seems to be a particularly fruitful time of the year",
       x = "Number of donations",
       y = "Campaign",
       caption = "FIGURE 9: Number of donors by campaign")

campaigns_summarised %>%
  mutate(campaign = fct_reorder(campaign, total_amount)) %>% 
  head(20) %>% 
  ggplot(aes(total_amount, campaign)) +
  geom_col() +
  scale_x_continuous(labels = dollar) +
  labs(title = "Christmas Bowl brings in the most money",
       subtitle = "Newsletter also seems to be a successful campaigning method",
       x = "Total donations",
       y = "Campaign",
       caption = "FIGURE 10: Total donation amount by campaign")

campaigns_summarised %>%
  mutate(campaign = fct_reorder(campaign, median_amount)) %>% 
  head(20) %>% 
  ggplot(aes(median_amount, campaign)) +
  geom_col() +
  scale_x_continuous(labels = dollar) +
  labs(title = "High value supporters understandably give more when they donate",
       subtitle = "Interestingly HV donors don't contribute so much to the total income as per FIG 11",
       x = "Median donation amount",
       y = "Campaign",
       caption = "FIGURE 11: Median donation amount by campaign")

campaigns_summarised %>%
  mutate(campaign = fct_reorder(campaign, max_amount)) %>% 
  head(20) %>% 
  ggplot(aes(max_amount, campaign)) +
  geom_col() +
  scale_x_continuous(labels = dollar) +
  labs(title = "The largest donations surface in the Christmas Bowl campaign",
       subtitle = "Although perhaps it's the HV donors who are donating to CB in these cases...",
       x = "Max donation amount",
       y = "Campaign",
       caption = "FIGURE 12: Max donation amount by campaign")
```

### Attitudes

```{r}
contacts %>% 
  mutate(comms_preference = str_replace_all(comms_preference, "[}]", ","),
         comms_preference = str_replace_all(comms_preference, "[{}]", "")) %>% 
  filter(!is.na(comms_preference)) %>% 
  unnest_tokens(comm_method, comms_preference) %>% 
  distinct(comm_method, supporter_id, .keep_all = TRUE) %>%
  group_by(comm_method) %>% 
  summarise(n = n(),
            num_gifts = sum(total_number_of_gifts),
            avg_gift_amount = mean(avg_gift_amount),
            total_gift_amount = sum(total_gifts)) %>% 
  mutate(comm_method = fct_reorder(comm_method, total_gift_amount)) %>% 
  ggplot(aes(comm_method, total_gift_amount)) +
  geom_col() +
  coord_flip() +
  scale_y_continuous(labels = dollar) +
  labs(title = "The communication preference seems to be a signal of willingness to give",
       subtitle = "Understandably people who say 'do not contact' give the least...",
       x = "Communication preference",
       y = "Total gift amount",
       caption = "FIGURE 13: Total gift amount by communication preference")
```

Finally, I just want to see how much of the supporter base (at least in the data we have) actually donated. It seems that there was a significant decrease in the number of supporters who decreased this year (2017) as opposed to last year (2016) and the year before.

```{r}
contacts %>% 
  mutate(donated_this_year = if_else(total_gifts_this_year > 0, "Donated", "Not donated"),
         donated_last_year = if_else(total_gifts_last_year > 0, "Donated", "Not donated"),
         donated_two_years_ago = if_else(total_gifts_two_years_ago > 0, "Donated", "Not donated")) %>% 
  select(starts_with("donated")) %>% 
  pivot_longer(cols = everything()) %>% 
  count(name, value) %>% 
  group_by(name) %>%
  mutate(pct_donated = n / sum(n)) %>% 
  filter(value == "Donated") %>% 
  mutate(order = case_when(name == "donated_this_year" ~ 1,
                           name == "donated_last_year" ~ 2, 
                           TRUE ~ 3)) %>% 
  arrange(order) %>% 
  ungroup() %>% 
  select(name, n, pct_donated)
```

----

## Returning briefly to the beginning

Now that I've done some exploratory data analysis (EDA), I want to return briefly to our motivation and build a plan for how to approach the questions. 

With segmentation, my initial thoughts are that there are probably signals in the underlying data that indicate how likely a person is to donate. If we can build a classifier that taps into these signals and returns a **probability of donating**, then we can use that to inform all of our questions - how we target people, how much we ask from them and what sort of messaging we send to them. 

After all, it makes sense to ask a bit more from someone you **know** is going to give anyway than from someone who is probably not going to give at all! `r emo::ji("moneybag")`

----

## Let the machines decide!

To figure out a **probability of donating**, we first need to frame the question correctly. We know that we have data on who donated for the years 2015 - 2017. With this in mind, I'm going to try and train a model to accurately predict the 2017 donations based on the 2015 and 2016 donations. 

`r emo::ji("bulb")` *This is called supervised learning - we already know the outcome in advance, so we can use that to our advantage and tune the model's hyperparameters (more on that below) to converge to the desired result.*

My machine learning workflow in this instance consisted of fitting a logistic regression model first, doing some feature engineering and hyperparameter tuning on the predictors, then moving to a more powerful type of model (XGBoost) and doing a bit more feature engineering and tuning. At each stage I measured the sensitivity, specificity and ROC AUC and used them as metrics to guide my hyperparameter settings.

`r emo::ji("bulb")` ***Specificity** measures the proportion of people who did not donate that are correctly identified as such. In other words, of everyone who didn't donate, how many did we classify correctly? **Sensitivity** is the same thing but for people who did donate. **Accuracy** is the total proportion of the data that was classified correctly.*

`r emo::ji("bulb")` *Feature engineering is when we compute new values based off data points that we have already. The hope is that these new **features** will create better representations of the data that will enable our model to learn more optimally.*

`r emo::ji("bulb")` *Think of **hyperparameters** as knobs in a machine learning model that you cannot estimate in advance, so you need to fiddle with them to find the right setting. Just like roasting vegetables - I can never find the right temperature on the oven!*

### Fiddling with hyperparameters

`r emo::ji("robot")` *All my workings related to tuning these models are accessible [here](https://github.com/chaz23/afp-interview/blob/main/scripts/modelling.Rmd).*

I'll briefly specify, just for illustrative purposes, how my metrics changed with each iterative tuning step. 

Remember, I'm trying to predict 2017 donations. I start off by trying to predict it using just log-transformed total gofts of 2016, and then at each step I add an additional predictor or do a tuning step. 

Note that when I add previous campaigns and non-financial actions I've removed any related to 2017 to avoid data leakage.

```{r}
tribble(
  ~ model, ~ step, ~ sensitivity, ~ specificity, ~ roc_auc, ~ accuracy,
  "logistic_regression", "log transform 2016 total gifts", 0.148, 0.989, 0.756, NA_real_,
  "logistic_regression", "use a downsampling under-ratio of 2", 0.607, 0.845, 0.756, NA_real_,
  "logistic_regression", "add total gifts", 0.578, 0.898, 0.801, NA_real_,
  "logistic_regression", "added total gifts 2 years ago", 0.564, 0.922, 0.813, NA_real_,
  "logistic_regression", "added total number of gifts", 0.612, 0.918, 0.833, NA_real_,
  "logistic_regression", "added gender", 0.610, 0.915, 0.849, NA_real_,
  "xgboost", "switched to xgboost", 0.685, 0.895, 0.877, NA_real_,
  "xgboost", "added previous campaigns", 0.715, 0.891, 0.898, NA_real_,
  "xgboost", "added communications preference", 0.746, 0.882, 0.905, 0.864,
  "xgboost", "added previous non-financial actions", 0.756, 0.895, 0.911, 0.876
) %>% 
  select(-model)
```

See how we've slowly improved our ability to accurately identify the people who will actually donate!

## Finally, some answers!

If I haven't lost you yet, we can now answer our original questions!

### How to segment the supporter base

In my mind, the question of segmentation is fundamentally linked to the **return on investment**. It makes sense to spend more effort on a supporter whose ROI is large. Luckily, our model gives us an idea on which supporters are easier targets.

Remember that it gave us not just an outcome of who donated and who didn't, but also a **probability of donating**. In fact, it was using this probability that it determined the outcome. Anyone who was over 50% was classified as someone who would donate in 2017. By adjusting this 50% threshold to some other value, we can shift the proportions of donors that we capture.

```{r}
threshold_data %>% 
  filter(.metric != "distance") %>% 
  mutate(.threshold = 1 - .threshold) %>%
  mutate(.metric = case_when(.metric == "sens"~ "sensitivity",
                             .metric == "spec"~ "specificity",
                             TRUE ~ .metric)) %>% 
  ggplot(aes(.threshold, .estimate, color = .metric)) +
  geom_line() +
  geom_vline(xintercept = 0.5, lty = "dashed", alpha = 0.7) +
  scale_x_continuous(labels = percent, breaks = seq(0, 1, 0.1)) +
  scale_y_continuous(labels = percent, breaks = seq(0, 1, 0.1)) +
  labs(title = "Shifting the dotted line to the right increases sensitivity",
       subtitle = "This means we capture more donors at the expense of targeting non-donors",
       color = "Metric",
       x = "Probability of donating",
       y = "Metric value",
       caption = "FIGURE 14: Variation of metrics according to the predicted probability of donating")
```

As the title and subtitle suggest, if the costs associated with engaging with donors is high, we would want to shift the line to the left. If the cost is low, we wouldn't care if we targeted more people who don't donate - we'd want to make sure we reached the maximum number of people who would donate.

Additionally, we might have different dotted lines at different thresholds (eg: 0-30%, 31-70%, 71-100%) and treat those categories differently.

Basically, this is one of the ways that I would approach segmentation.

### How much can we ask?

To answer this, I would adapt existing strategies of asking and modify them based on the additional information that we have.

For example, I might calculate the average of the most recent gift and largest gift amount (recommended strategy), and then multiply it by a value between 10% and 25% based on the probability of donating and the number of times donated previously (incorporating additional info). Something like: 

$Donation \ ask = \frac{(Most \ recent \ gift \ + \ Largest \ gift \ amount)}{2} * (110\%+15\% * f(p_{donating},n_{donations}))$

where $f$ is bounded between $0$ and $1$.

### What do we send?



### Ideas for the future




