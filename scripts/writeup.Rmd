---
title: "Act for Peace Interview: Data Analysis and Write-up"
author: "Charith Wijewardena"
output: 
  html_document: 
    toc: yes
    toc_depth: 4
toc-title: "Contents"
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE, out.width = "90%", fig.align = "center")
```

```{r}
library(dplyr)
library(forcats)
library(stringr)
library(tidyr)
library(ggplot2)
library(scales)
library(showtext)
library(ggthemes)
library(tidytext)
library(tidymodels)
library(textrecipes)

load("C:/Users/chari/Documents/afp-data/clean_data.Rda")
load("C:/Users/chari/Documents/afp-data/raw_data.Rda")
load("C:/Users/chari/Documents/afp-data/modelling_data.Rda")
```

```{r cache=TRUE}
font_add_google("Open Sans", family = "Open Sans Semibold", regular.wt = 600)
font_add_google("IBM Plex Sans")
font_add_google("IBM Plex Mono")
```

```{r}
showtext_auto()

ret <- theme_minimal() +
      theme(
        plot.title = element_text(family = "Open Sans Semibold", size = 20),
        plot.subtitle = element_text(family = "IBM Plex Sans", size = 18),
        plot.caption = element_text(family = "IBM Plex Mono", size = 16, colour = "grey50", hjust = 0.5),
        axis.title = element_text(family = "IBM Plex Sans", size = 18),
        axis.text = element_text(family = "IBM Plex Mono", size = 16.5),
        legend.title = element_text(family = "Open Sans Semibold", size = 14),
        legend.text = element_text(family = "IBM Sans Plex", size = 14),
        panel.grid.major.x = element_line(colour = "white", linetype = "dashed"),
        panel.grid.minor.x = element_line(colour = "white", linetype = "dashed"),
        panel.grid.major.y = element_line(colour = "grey75", linetype = 2, size = 0.3),
        panel.grid.minor.y = element_line(colour = "grey75", linetype = 2, size = 0.3)
      )

theme_set(ret)
```

----

## Introduction

### Managing expectations

Before I begin, please allow me to lay the boundaries of this analysis. 

Given that the purpose of this task is simply to gain some insight into my thought process, methodology and personality, I'm going to take on a narrative style in this write-up and guide you through my thought process as I explored the data. There are many paths that I could have gone down in trying to answer the questions presented. The approach that I took was to simply pick one of those after doing some exploratory data analysis and see where that led. In real life, this would have been an iterative process of exploration and evaluation. The questions we orignally asked may have even evolved based on our findings. 

However, I decided at the start not to iterate on my findings or modelling outcomes regardless of model accuracy. Given the motivation of this task as well as the limited time available, this seemed reasonable.

Anyway, I like to explain things so I hope you find this enjoyable at the very least! Who knows, perhaps you'll even learn something new!! `r emo::ji("sparkles")`

### Setting up computation

All computation was performed in R using R version 4.1.2. You can access all my code via Github [here](https://github.com/chaz23/afp-interview). Throughout this document I will add links to scripts that I wrote for each section if relevant. I also used the **renv** package to produce as reproducible an environment as possible. 

`r emo::ji("bulb")` ***renv** manages all the packages and their versions that I have used for this project. If you were to clone my repo and run my code, the renv lockfile would ensure that you used the same R and package versions that I did.* 

However, as I have kept all input and output data on my local machine in the interests of confidentiality (i.e not storing it in a Github public repository), this is mostly for illustrative purposes as far as this write-up goes. In real life, I like to maintain transparency and reproducibility.

### Why are we here and what's coming next?

Analysis without a motivation is often aimless, so I'm glad that you have provided some questions to keep us on track!

* How these individuals might be segmented and why?
* How would the donation ask in their next communication be calculated and why?
* What might you send to the groups you identify and what might you not send to them and why?
* How would you improve on these things in the future?

To keep my data analysis as methodical as I can here, I've tried to divide my workflow into 3 stages. (It's usually an iterative process but remember I said I'm not iterating here). The 3 stages are:

* **Validation:** Evaluating data cleanliness and self-consistency, handling missing data and outliers etc.
* **Description and modelling:** Looking at distributions, correlations etc. Articulating objective interpretations of the data that we can all agree on, and then modelling based on those.
* **Evaluation:** Given the descriptions and modelling, **how do we answer our original questions?** 

Cool, now I'll get straight into it.

----

## Introducing ourselves to the data

### Towards internal consistency

Before working with data directly, I often take some time to check its level of cleanliness and internal consistency. After all, garbage in equals garbage out. One thing I discovered early on is that the data between 2 tables - Contacts and Transactions - does not seem to match up. I'll remind you briefly what columns we had in the original data.

**Contacts:**

```{r}
contacts_raw %>% str()
```

**Transactions:**

```{r}
transactions_raw %>% str()
```

It appears that the sum of transactions for **7,592 out of 32,188 supporters** in the Transactions table (sum of the `Amount` column) was different to the value of `Total Gifts` for those same supporters in the Contacts table.

```{r}
contacts %>% 
  left_join((transactions %>% 
               group_by(supporter_id) %>% 
               summarise(amount = sum(amount))), 
            by = "supporter_id") %>% 
  filter(total_gifts < amount) %>% 
  select(supporter_id, total_gifts_from_contacts = total_gifts, total_amount_from_transactions = amount) %>% 
  
  mutate(diff = abs(total_gifts_from_contacts - total_amount_from_transactions)) %>% 
  filter(diff <= 10)
```

My initial hunch was that this could be a rounding error, for example where `r dollar(472)` in one table was recorded as `r dollar(470)` in another. Yet that didn't seem to be the case as the following frequency histogram seems to suggest.

```{r}
contacts %>% 
  left_join((transactions %>% 
               group_by(supporter_id) %>% 
               summarise(amount = sum(amount))), 
            by = "supporter_id") %>% 
  filter(total_gifts < amount) %>% 
  select(supporter_id, total_gifts_from_contacts = total_gifts, total_amount_from_transactions = amount) %>% 
  mutate(diff = total_amount_from_transactions - total_gifts_from_contacts) %>% 
  ggplot(aes(diff)) +
  geom_histogram(color = "grey") +
  scale_x_log10(labels = dollar) +
  labs(title = "Discrepancy between Contacts and Transactions isn't a rounding error",
       subtitle = "Many transactions appear to be missing entirely from Contacts",
       x = "Difference in total gifts between Contacts and Transactions",
       y = "Number of supporters",
       caption = "FIGURE 1: Discrepancy between total gifts in Contacts and Transactions tables (on log scale)")
```

Given that about a quarter of the Transactions dataset is inconsistent with Contacts, this is a **huge red flag** and in real life I would have investigated this further to update my understanding and check whether I had made some mistake. However, it does seem that ~57% of the discrepancies are only off by $10 or less, so **perhaps it's a mix of rounding errors and something else**. 

For now I chose to ignore this fact and move on.

### Outliers, missing data and augmentation

`r emo::ji("robot")` *The script that I used to clean the raw data is accessible [here](https://github.com/chaz23/afp-interview/blob/main/scripts/clean_raw_data.R).*

`r emo::ji("robot")` *The script that I used to get latitude and longitude coordinates is accessible [here](https://github.com/chaz23/afp-interview/blob/main/scripts/create_postcode_data.R).*

I've created a "master" dataset by merging what I feel are the relevant parts of Transactions and Non-Financial Actions into Contacts, so I only have to work with one table. I want to get a sense of the overall distributions of my data, and understand **how much data is missing**.

`r emo::ji("bulb")` *Understanding the causes of missing data is especially important if we want to feed our data to a machine learning model, as the vast majority of them do not like missing values. In those cases, we would need to impute those values, drop them or figure out another way to handle the problem.* 

Some preparatory steps I took to clean the data are as follows:

* Renamed columns according to the [R style guide](https://style.tidyverse.org/syntax.html#syntax).
* Joined an [external postcodes dataset](https://gist.github.com/randomecho/5020859) to:
  * Get supporter mailing location (at the postcode level) in latitude and longitude.
  * Fill in missing values for the `state` column where the postcode was known. Note that this may yield slight inaccuracies in edge cases where multiple states share the same postcode.
* Cleaned the `state` column for consistency - eg: change N.S.W to NSW etc.
* Removed deceased supporters as they might confuse our model if we decide to use one later on to predict giving.
* Added a `nonfin_action` column to Contacts to indicate if a supporter has previously participated in any non-financial actions.
* Added average gift amounts for each of the time periods presented. (Eg: `avg_gift_amount_last_year`).
* Joined the Contacts and Transactions tables together to indicate what campaigns and source channels a supporter had participated in before. Having the campaigns and channels in this format means that I can possibly tokenize this data later if I want to feed it to a machine learning model. **I removed information related to 2017 to avoid data leakage.**

`r emo::ji("bulb")` *Data leakage is when information from outside the training dataset is used to build a model. As you'll see later, I try to predict total donations in 2017 while pretending that I live in the year 2016 - if I used information from 2017, that would be an unfair and misleading advantage for my model.*

```{r}
contacts %>% 
  select(supporter_id, previous_campaigns) %>% 
  filter(previous_campaigns != "Unknown")
```

Furthermore, I took **"this year" to mean the calendar year 2017.**

This is what my new tidied dataset looks like, ready for analysis. Here I've split the variables by data type (character and numeric). What I'm usually interested in seeing is the completion rate, which tells me the fraction of missing values, the number of unique entries in the character variables and the histograms of the numeric variables. What stands out to me is how much missing information we have on supporters when it comes to age. This is a pity, as age could well be a good signal when it comes to predicting giving.

The histograms of the gift numbers and totals seem to indicate a log-normal distribution. Understandably, many people give small amounts, while a handful donate massively. There's a mix of demographic (gender, religion, age, location), attitudinal (communication preference) and behavioural (number of gifts given and average gift amount) variables.

```{r}
contacts %>% skimr::skim() %>% skimr::partition()
```

----

## Diving deep with EDA

This is where I begin to build some plots to start getting a feel for the data. I'll show you a handful of the ones I found interesting.

### Demographics

`r emo::ji("warning")` *Bear in mind that 88% of the data was not included in the following graphs containing `age` as it was unknown. However, let's assume for now that the values for age that we have are uniformly sampled from the population.*

```{r}
contacts %>% 
  filter(!is.na(age)) %>% 
  mutate(age_bin = 5 * (age %/% 5),
         age_bin = factor(age_bin)) %>%
  ggplot(aes(age_bin, avg_gift_amount, fill = gender)) +
  geom_boxplot() +
  coord_cartesian(ylim = c(0, 250)) +
  labs(title = "Males appear to donate larger amounts and have a wider spread than females",
       x = "Age",
       y = "Average donation amount",
       fill = "Gender",
       caption = "FIGURE 2: Boxplot of average donation amount by age and gender") +
  theme(legend.position = "top")

contacts %>% 
  filter(total_gifts > 0) %>% 
  ggplot(aes(age, avg_gift_amount, color = gender)) +
  geom_point(position = "jitter", alpha = 0.2) +
  scale_y_log10(labels = dollar) +
  geom_smooth() +
  labs(title = "Another perspective: avg donation amount vs. age and gender",
       subtitle = "Beware: the fitted line only looks flat because the y-axis is log-transformed!",
       x = "Age",
       y = "Average donation amount",
       color = "Gender",
       caption = "FIGURE 3: Scatterplot of average donation amount by age and gender") +
  theme(legend.position = "top")
```

To dig a bit further into this, I took `age`, log-transformed `avg_gift amount` and `num_gifts_last_365_days` and then did a pairwise correlation between them all. The values below are the correlation coefficients. The value 0.56 suggests that there is a moderately strong relationship between age and average gift amount. 

```{r}
contacts %>% 
  select(age, avg_gift_amount, num_gifts_last_365_days) %>% 
  mutate(avg_gift_amount = log10(avg_gift_amount + 0.1),
         num_gifts_last_365_days = log10(num_gifts_last_365_days + 0.1)) %>% 
  filter(!is.na(age)) %>% 
  corrr::correlate() %>% 
  corrr::fashion()
```

```{r}
contacts %>% 
  ggplot(aes(age, fill = gender)) +
  geom_histogram(binwidth = 2, color = "grey", position = "fill") +
  labs(title = "More females donate across all age groups than males",
       subtitle = "Do younger donors not like to disclose their gender?",
       x = "Age",
       y = "Proportion of supporters",
       fill = "Gender",
       caption = "FIGURE 4: Gender proportions of donors across age groups") +
  scale_y_continuous(labels = percent) +
  theme(legend.position = "top")

contacts %>% 
  ggplot(aes(age, fill = religion)) +
  geom_histogram(binwidth = 2, color = "grey") +
  labs(title = "Most older donors identify as Christian",
       x = "Age",
       y = "Number of supporters",
       fill = "Religion",
       caption = "FIGURE 5: Number of donors by age and religion") +
  theme(legend.position = "top")
```

```{r}
aus_map_data <- map_data("world") %>% 
  as_tibble() %>% 
  filter(region == "Australia") %>% 
  filter(long < 155)

contacts %>% 
  filter(country == "Australia") %>% 
  filter(lon > 112) %>%
  ggplot(aes(lon, lat)) +
  geom_polygon(aes(long, lat, group = group), data = aus_map_data, fill = "white", color = "grey") +
  geom_point(aes(color = state, size = avg_gift_amount), alpha = 0.2) +
  theme_map() +
  labs(title = "Most larger donors are populated around the major cities",
       x = "Age",
       y = "Number of supporters",
       fill = "State",
       size = "Avg Gift Amount",
       caption = "FIGURE 6: Donor locations around Australia") +
  theme(legend.position = "top",
        legend.text = element_text(family = "IBM Plex Mono", size = 16),
        legend.title = element_text(family = "IBM Plex Mono", size = 16),
        plot.title = element_text(family = "Open Sans Semibold", size = 20),
        plot.caption = element_text(family = "IBM Plex Mono", size = 16, colour = "grey50", hjust = 0.5))
```

```{r}
contacts %>% 
  filter(!is.na(state)) %>% 
  filter(country == "Australia") %>%
  ggplot(aes(total_gifts + 1, fill = state)) +
  geom_histogram(color = "grey", position = "fill") +
  scale_x_log10(labels = dollar) +
  scale_y_continuous(labels = percent) +
  labs(title = "The proportion of donors in each group increases for ACT",
       subtitle = "Do ACT donors generally donate more?",
       x = "Total amount donated",
       y = "Proportion of supporters",
       fill = "State",
       caption = "FIGURE 7: Proportion of donors in each donation bracket by state") +
  theme(legend.position = "top")

contacts %>% 
  filter(!is.na(age) & !is.na(state)) %>% 
  ggplot(aes(age, fill = state)) +
  geom_histogram(color = "grey", binwidth = 5, position = "fill") +
  scale_y_continuous(labels = percent) +
  labs(title = "Or could this increase be correlated with age?",
       subtitle = "Could we have an older ACT population in our donor base?",
       x = "Age",
       y = "Proportion of supporters",
       fill = "State",
       caption = "FIGURE 8: Proportion of donors in each age bracket by state") +
  theme(legend.position = "top")
```

Trying to correlate age vs. total gifts does show a moderately strong linear relationship. It makes sense - the longer you've lived, the more time you've had to donate! If this is true, we should watch out for this multicollinearity later on if we want to use these variables as predictors in a model. But it needs further looking into.

```{r}
contacts %>% 
  select(age, total_gifts) %>%
  mutate(total_gifts = log10(total_gifts + 0.1)) %>% 
  na.omit() %>% 
  corrr::correlate() %>% 
  corrr::fashion()
```

### Behaviours

```{r}
campaigns_summarised <- transactions %>%
  mutate(source = str_replace_all(source, "-", " "),
         source = str_replace_all(source, "[0-9]", " ")) %>% 
  unnest_tokens(campaign, source, to_lower = FALSE) %>% 
  left_join(campaign_list, by = "campaign") %>% 
  mutate(campaign = if_else(!is.na(desc), paste0(campaign, " (", desc, ")"), campaign)) %>% 
  group_by(campaign) %>% 
  summarise(n = n(),
            min_amount = min(amount),
            max_amount = max(amount),
            median_amount = median(amount),
            avg_amount = mean(amount),
            total_amount = sum(amount)) %>% 
  arrange(desc(n))

campaigns_summarised %>%
  mutate(campaign = fct_reorder(campaign, n)) %>% 
  head(20) %>% 
  ggplot(aes(n, campaign)) +
  geom_col() +
  labs(title = "Regular givers and Christmas Bowl are the highest volume campaigns",
       subtitle = "EOFY also seems to be a particularly fruitful time of the year",
       x = "Number of donations",
       y = "Campaign",
       caption = "FIGURE 9: Number of donors by campaign")

campaigns_summarised %>%
  mutate(campaign = fct_reorder(campaign, total_amount)) %>% 
  head(20) %>% 
  ggplot(aes(total_amount, campaign)) +
  geom_col() +
  scale_x_continuous(labels = dollar) +
  labs(title = "Christmas Bowl brings in the most money",
       subtitle = "Newsletter also seems to be a successful campaigning method",
       x = "Total donations",
       y = "Campaign",
       caption = "FIGURE 10: Total donation amount by campaign")

campaigns_summarised %>%
  mutate(campaign = fct_reorder(campaign, median_amount)) %>% 
  head(20) %>% 
  ggplot(aes(median_amount, campaign)) +
  geom_col() +
  scale_x_continuous(labels = dollar) +
  labs(title = "High value supporters understandably give more when they donate",
       subtitle = "Interestingly HV donors don't contribute so much to the total income as per FIG 11",
       x = "Median donation amount",
       y = "Campaign",
       caption = "FIGURE 11: Median donation amount by campaign")

campaigns_summarised %>%
  mutate(campaign = fct_reorder(campaign, max_amount)) %>% 
  head(20) %>% 
  ggplot(aes(max_amount, campaign)) +
  geom_col() +
  scale_x_continuous(labels = dollar) +
  labs(title = "The largest donations surface in the Christmas Bowl campaign",
       subtitle = "Although perhaps it's the HV donors who are donating to CB in these cases...",
       x = "Max donation amount",
       y = "Campaign",
       caption = "FIGURE 12: Max donation amount by campaign")
```

### Attitudes

```{r}
contacts %>% 
  mutate(comms_preference = str_replace_all(comms_preference, "[}]", ","),
         comms_preference = str_replace_all(comms_preference, "[{}]", "")) %>% 
  filter(!is.na(comms_preference)) %>% 
  unnest_tokens(comm_method, comms_preference) %>% 
  distinct(comm_method, supporter_id, .keep_all = TRUE) %>%
  group_by(comm_method) %>% 
  summarise(n = n(),
            num_gifts = sum(total_number_of_gifts),
            avg_gift_amount = mean(avg_gift_amount),
            total_gift_amount = sum(total_gifts)) %>% 
  mutate(comm_method = fct_reorder(comm_method, total_gift_amount)) %>% 
  ggplot(aes(comm_method, total_gift_amount)) +
  geom_col() +
  coord_flip() +
  scale_y_continuous(labels = dollar) +
  labs(title = "The communication preference seems to be a signal of willingness to give",
       subtitle = "Understandably people who say 'do not contact' give the least...",
       x = "Communication preference",
       y = "Total gift amount",
       caption = "FIGURE 13: Total gift amount by communication preference")
```

Finally, I just want to see how much of the supporter base (at least in the data we have) actually donated. It seems that there was a significant decrease in the number of supporters who decreased this year (2017) as opposed to last year (2016) and the year before.

```{r}
contacts %>% 
  mutate(donated_this_year = if_else(total_gifts_this_year > 0, "Donated", "Not donated"),
         donated_last_year = if_else(total_gifts_last_year > 0, "Donated", "Not donated"),
         donated_two_years_ago = if_else(total_gifts_two_years_ago > 0, "Donated", "Not donated")) %>% 
  select(starts_with("donated")) %>% 
  pivot_longer(cols = everything()) %>% 
  count(name, value) %>% 
  group_by(name) %>%
  mutate(pct_donated = n / sum(n)) %>% 
  filter(value == "Donated") %>% 
  mutate(order = case_when(name == "donated_this_year" ~ 1,
                           name == "donated_last_year" ~ 2, 
                           TRUE ~ 3)) %>% 
  arrange(order) %>% 
  ungroup() %>% 
  select(name, n, pct_donated)
```

----

## Returning briefly to the beginning

Now that I've done some exploratory data analysis (EDA), I want to return briefly to our initial questions and build a plan for how to approach them. 

With segmentation, I feel that there are probably signals in the underlying data that indicate how likely a person is to donate. If we can build a classifier that taps into these signals and returns a **probability of donating**, then we can use that to inform all of our questions - how we target people, how much we ask from them and maybe even what sort of messaging we send to them. 

After all, it makes sense to ask a bit more from someone you **know** is going to give anyway than from someone who is probably not going to give at all! `r emo::ji("moneybag")`

----

## Let the machines decide!

`r emo::ji("robot")` *The script that I used to build the following models and tune their hyperparameters is accessible [here](https://github.com/chaz23/afp-interview/blob/main/scripts/modelling.Rmd).*

To figure out a **probability of donating**, we first need to frame the question correctly. We know that we have data on who donated for the years 2015 - 2017. With this in mind, I'm going to try and train a model to accurately predict the 2017 donations based on the 2015 and 2016 donations. 

`r emo::ji("bulb")` *This is called supervised learning - we already know the outcome in advance, so we can use that to our advantage and tune the model's hyperparameters (more on that below) to converge to the desired result.*

My machine learning workflow in this instance consisted of fitting a logistic regression model first, doing some feature engineering and hyperparameter tuning on the predictors, then moving to a more powerful type of model (XGBoost) and doing a bit more feature engineering and tuning. At each stage I measured the sensitivity and specificity and used them as metrics to guide my hyperparameter settings.

`r emo::ji("bulb")` ***Specificity** measures the proportion of people who did not donate that are correctly identified as such. In other words, of everyone who didn't donate, how many did we classify correctly? **Sensitivity** is the same thing but for people who did donate. **Accuracy** is the total proportion of the data that was classified correctly.*

`r emo::ji("bulb")` *Feature engineering is when we compute new values based off data points that we have already. The hope is that these new **features** will create better representations of the data that will enable our model to learn more optimally.*

`r emo::ji("bulb")` *Think of **hyperparameters** as knobs in a machine learning model that you cannot estimate in advance, so you need to fiddle with them to find the right setting.*

### Fiddling with hyperparameters

I'll briefly specify, just for illustrative purposes, how my metrics changed with each iterative tuning step. 

Remember, I'm trying to predict 2017 donations. I start off by trying to predict it using just log-transformed total gofts of 2016, and then at each step I add an additional predictor or do a tuning step. 

Note that when I add previous campaigns and non-financial actions I've removed any related to 2017 to avoid data leakage.

```{r}
tribble(
  ~ model, ~ step, ~ sensitivity, ~ specificity, ~ roc_auc, ~ accuracy,
  "logistic_regression", "log transform 2016 total gifts", 0.148, 0.989, 0.756, NA_real_,
  "logistic_regression", "use a downsampling under-ratio of 2", 0.607, 0.845, 0.756, NA_real_,
  "logistic_regression", "add total gifts", 0.578, 0.898, 0.801, NA_real_,
  "logistic_regression", "added total gifts 2 years ago", 0.564, 0.922, 0.813, NA_real_,
  "logistic_regression", "added total number of gifts", 0.612, 0.918, 0.833, NA_real_,
  "logistic_regression", "added gender", 0.610, 0.915, 0.849, NA_real_,
  "xgboost", "switched to xgboost", 0.685, 0.895, 0.877, NA_real_,
  "xgboost", "added previous campaigns", 0.715, 0.891, 0.898, NA_real_,
  "xgboost", "added communications preference", 0.746, 0.882, 0.905, 0.864,
  "xgboost", "added previous non-financial actions", 0.756, 0.895, 0.911, 0.876
) %>% 
  select(-model)
```

See how we've slowly improved our ability to accurately identify the people who will actually donate!

----

## Finally, some answers!

If I haven't lost you yet, we can now answer our original questions!

### How to segment the supporter base

In my mind, the question of segmentation is fundamentally linked to the **return on investment**. 

$ROI = Donation - Cost \ of \ engagement$

For each supporter, we need to categorize them based on those two terms **donation** and **cost of engagement**. Let's use the average gift amount to parametrize donation.

$Donation=f(avg\_gift\_amount)$

```{r}
contacts %>% 
  ggplot(aes(avg_gift_amount)) +
  geom_histogram(color = "grey", bins = 60) +
  scale_x_log10(labels = dollar) +
  labs(title = "Average gift amount allows us to parametrize the 'Donation' term",
       x = "Average gift amount",
       y = "Number of supporters",
       caption = "FIGURE 14: Frequency count of average gift amount")
```

Now we need to parametrize the "cost of engagement". Luckily, our model can help us out here.

Remember that it gave us not just an outcome of who donated and who didn't, but also a **probability of donating**. In fact, it was using this probability that it determined the outcome. Anyone who was deemed to have a "probability of donating" of over 50% was classified as someone who would donate in 2017. 

**Someone with a high probability will have a low cost of engagement**. It makes sense - they don't need much prodding to donate! 

So we can assume that cost of engagement is a function of the probability of donating.

$Cost \ of \ engagement=f(p_{donating})$

The following chart shows how the model distributed supporters across the domain of [0, 1] when it came to assigning this probability of donating. 

```{r}
threshold_data %>% 
  filter(.metric != "distance") %>% 
  mutate(.threshold = 1 - .threshold) %>%
  mutate(.metric = case_when(.metric == "sens"~ "sensitivity",
                             .metric == "spec"~ "specificity",
                             TRUE ~ .metric)) %>% 
  ggplot(aes(.threshold, .estimate, color = .metric)) +
  geom_line() +
  geom_vline(xintercept = 0.5, lty = "dashed", alpha = 0.7) +
  scale_x_continuous(labels = percent, breaks = seq(0, 1, 0.1)) +
  scale_y_continuous(labels = percent, breaks = seq(0, 1, 0.1)) +
  labs(title = "Shifting the dotted line to the right increases sensitivity",
       subtitle = "This means we capture more donors at the expense of excluding non-donors",
       color = "Metric",
       x = "Probability of donating",
       y = "Metric value",
       caption = "FIGURE 15: Variation of metrics according to the predicted probability of donating")
```

Now we can combine the two to figure out an optimal segmentation strategy. 

In the following figure, I have done exactly that to showcase how we can **create regions in the plot to segment supporters**. `r emo::ji("sparkles")`

```{r}
test %>% 
  mutate(donated = factor(donated)) %>% 
  bind_cols(predict(xgb_fit, new_data = test, type = "prob")) %>% 
  left_join(contacts %>% select(supporter_id, avg_gift_amount), by = "supporter_id") %>% 
  ggplot(aes(.pred_Donated, avg_gift_amount + 0.1, color = donated)) +
  geom_point(alpha = 0.15, position = "jitter") +
  scale_x_continuous(labels = percent) +
  scale_y_log10(labels = dollar) +
  labs(title = "The X and Y axes parametrize the cost and return respectively",
       subtitle = "We can create regions in this plot to segment donors in the future",
       color = "Actually donated?",
       x = "Probability of donating",
       y = "Historical average gift amount",
       caption = "FIGURE 16: Parametrization of the ROI on the test data fed to XGBoost") +
  theme(legend.position = "top")
```

### How much can we ask?

To answer this, I would adapt existing strategies of asking and modify them based on the additional information that we have.

For example, I might calculate the average of the most recent gift and largest gift amount (recommended strategy), and then multiply it by a value between 10% and 25% based on the probability of donating and the number of times donated previously (incorporating additional info). Something like: 

$Donation \ ask = \frac{(Most \ recent \ gift \ + \ Largest \ gift \ amount)}{2} * (110\%+15\% * f(p_{donating},n_{donations}))$

where $f$ is bounded between $0$ and $1$.

Along with this "recommended" amount, I would have 3 other options as well - 2 numerical options and 1 "Other" option where the supporter is free to choose their own donation amount.

### What do we send?

Some thoughts I had are:

* After segmenting the groups as specified above, we could tailor our communication to them accordingly. For example, the "high value" segment could perhaps be reached by telephone, or some other time-intensive means, whereas the lower groups could be reached via email etc.
* Going on the insights derived from Figure 5, we could target younger groups with more secular messaging, in line with the way they identify.
* Although I haven't done analysis into this, it might be interesting to see whether there is a temporal/seasonal correlation at the supporter level in the way that they donate. If so, we could possibly send them some form of messaging/newsletter a few weeks before their predicted donation date as a "reminder".

### Ideas for the future

* While it's great to segment our existing supporter base, we should also be looking to expand it. One idea I had was to use Facebook ads to target individuals based on markers that we have identified. If this hasn't been implemented already, it could be a great way to spread our reach.
* Using fancy graphics - static or interactive - could be a great way to spice up communications, be it newsletters or otherwise. People like things that look good, and they will feel more engaged. 

----

I hope that this analysis has been insightful - looking forward to discussing further! `r emo::ji("pray")`