---
title: "Act for Peace Interview: Data Analysis and Write-up"
author: "Charith Wijewardena"
output: 
  html_document: 
    toc: yes
    toc_depth: 4
toc-title: "Contents"
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE, out.width = "90%", fig.align = "center")
```

```{r}
library(dplyr)
library(forcats)
library(stringr)
library(ggplot2)
library(scales)
library(showtext)
library(ggthemes)
library(tidytext)

load("C:/Users/chari/Documents/afp-data/clean_data.Rda")
```

```{r cache=TRUE}
font_add_google("Open Sans", family = "Open Sans Semibold", regular.wt = 600)
font_add_google("IBM Plex Sans")
font_add_google("IBM Plex Mono")
```

```{r}
showtext_auto()

ret <- theme_minimal() +
      theme(
        plot.title = element_text(family = "Open Sans Semibold", size = 20),
        plot.subtitle = element_text(family = "IBM Plex Sans", size = 18),
        plot.caption = element_text(family = "IBM Plex Mono", size = 16, colour = "grey50", hjust = 0.5),
        axis.title = element_text(family = "IBM Plex Sans", size = 18),
        axis.text = element_text(family = "IBM Plex Mono", size = 16.5),
        legend.title = element_text(family = "Open Sans Semibold", size = 14),
        legend.text = element_text(family = "IBM Sans Plex", size = 14),
        panel.grid.major.x = element_line(colour = "white", linetype = "dashed"),
        panel.grid.minor.x = element_line(colour = "white", linetype = "dashed"),
        panel.grid.major.y = element_line(colour = "grey75", linetype = 2, size = 0.3),
        panel.grid.minor.y = element_line(colour = "grey75", linetype = 2, size = 0.3)
      )

theme_set(ret)
```

----

## Introduction

### Scope of the analysis

First of all, please allow me to lay the boundaries and scope of this task and write-up. I understand that the purpose of this task is simply to gain some insight into my thought process, methodology and personality, and not to build the best segmentation model. 

Here I will take on a narrative style in this write-up and guide you through my thought process as I explore the data. There are many paths that one could go down when trying to answer the questions presented. I will simply pick one of those after doing some exploratory data analysis and see where that leads. In real life, this would be an iterative process of exploration and evaluation, as the questions we have originally asked will evolve based on our findings. I will not be updating the questions, nor iterating on my modelling outcomes regardless of model accuracy. Given the motivation of this task as well as the limited time available, this seems like a sensible approach.

Anyway, I hope you find this enjoyable at the very least! Who knows, perhaps you'll even learn something new!! `r emo::ji("sparkles")`

### Computation

All computation is performed in R using R version 4.1.2. You can access all my code via Github [here](https://github.com/chaz23/afp-interview). Throughout this document I will add links to scripts that I wrote for each section if relevant.

Reproducibility is an important part of good data science, so I have used the **renv** package to produce as reproducible an environment as possible. However, as I have kept all input and output data on my local machine in the interests of confidentiality (i.e not storing it in a Github public repository), this will affect reproducibility in this instance.

### Approach

While data science is partly art and partly science, I like to approach data analysis tasks in as principled and methodical a manner as I can. Usually, this involves 3 steps:

* **Validation:** 

Exploring and evaluating the cleanliness and self-consistency of the data. Handling missing data, making sure that data points match up with each other, understanding the meaning behind each variable, understanding the nature of outlying values 

* **Description:**

Exploratory data analysis. Slicing the data

* Evaluation


### Motivation

Analysis without a motivation is often aimless, so I'm glad that you have provided some questions to keep us on track!

* How these individuals might be segmented and why?
* How would the donation ask in their next communication be calculated and why?
* What might you send to the groups you identify and what might you not send to them and why?
* How would you improve on these things in the future?

These are some interesting questions, so let's dive into the data to see what we find!

----

## Data preparation

Before working with the data directly, I take some time to check its level of cleanliness and internal consistency. After all, garbage in equals garbage out. I won't include all the details, but I made some assumptions along the way:

* 7,592 out of the 32,188 supporters in the Transactions table had a `total_gifts` value (sum of all gifts across time in the Contacts table) lower than the sum of their individual transactions. Since this is about a quarter of the dataset, I chose to ignore this fact, although in reality with access to the complete dataset I would have investigated this further as it is a huge indication that the two datasets are not internally consistent.

```{r}
contacts %>% 
  left_join((transactions %>% 
               group_by(supporter_id) %>% 
               summarise(amount = sum(amount))), 
            by = "supporter_id") %>% 
  filter(total_gifts < amount) %>% 
  select(supporter_id, total_gifts_from_contacts = total_gifts, total_amount_from_transactions = amount)
```

```{r}
contacts %>% 
  left_join((transactions %>% 
               group_by(supporter_id) %>% 
               summarise(amount = sum(amount))), 
            by = "supporter_id") %>% 
  filter(total_gifts < amount) %>% 
  select(supporter_id, total_gifts_from_contacts = total_gifts, total_amount_from_transactions = amount) %>% 
  mutate(diff = total_amount_from_transactions - total_gifts_from_contacts) %>% 
  ggplot(aes(diff)) +
  geom_histogram(color = "grey") +
  scale_x_log10(labels = dollar) +
  labs(title = "Discrepancy between Contacts and Transactions isn't a rounding error",
       subtitle = "Many transactions appear to be missing entirely from Contacts",
       x = "Difference in total gifts between Contacts and Transactions",
       y = "Number of supporters",
       caption = "FIGURE 1: Discrepancy between total gifts in Contacts and Transactions tables")
```


* Given that I was told that the datasets were compiled at the same time, I took "this year" to mean the calendar year 2017.

For this project, given the scope that I'm working within, I'm going to create a "master" dataset by merging what I feel are the relevant parts of Transactions and Non-Financial Actions into Contacts. 

Some steps I took to clean the data are as follows:

* Renamed columns according to the [R style guide](https://style.tidyverse.org/syntax.html#syntax).
* Joined an [external postcodes dataset](https://gist.github.com/randomecho/5020859) to:
  * Get supporter mailing location (at the postcode level) in latitude and longitude.
  * Fill in missing values for the `state` column where the postcode was known. Note that this may yield slight inaccuracies in edge cases where multiple states share the same postcode.
* Cleaned the `state` column for consistency - eg: change N.S.W to NSW etc.
* Removed deceased supporters as they might confuse our model if we decide to use one later on to predict giving.
* Joined the Contacts and Transactions tables together to indicate what campaigns a supporter had participated in before. Having the campaigns in this format means that I can possibly tokenize this data later if I want to feed it to a machine learning model.

```{r}
contacts %>% 
  select(supporter_id, previous_campaigns) %>% 
  na.omit()
```

* Added a `nonfin_action` column to Contacts to indicate if a supporter has previously participated in any non-financial actions. Given the unbalanced classes and low number of distinct items in Non-Financial Actions I'm not going to spend too much time with it. Additionally, I'm going to make the assumption that anyone not in this table has never participated in a non-financial action.

* Added average gift amounts for each of the time periods presented. (Eg: `avg_gift_amount_last_year`).

----

## Data exploration

After I've cleaned the data to an acceptable level, I like to have a look at the characteristics of each variable. Notice how we're moving from the *validation* stage to the *description* stage. Descriptions give us objective interpretations that we can all agree on.

Here I've split the variables by data type (character and numeric). What I'm usually interested in seeing is the completion rate, which tells me the fraction of missing values, the number of unique entries in the character variables and the histograms of the numeric variables.

The histograms of the gift numbers and totals seem to indicate a log-normal distribution which we'll check later. Understandably, many people give small amounts, while a handful donate massively. There's a mix of demographic variables (gender, religion, age, location), attitudinal (communication preference) and behavioural (number of gifts given and average gift amount).

```{r}
contacts %>% skimr::skim() %>% skimr::partition()
```

This is where I begin to build some plots to start getting a feel for the data. I'll show you a handful of the ones I found interesting.

```{r}
contacts %>% 
  filter(!is.na(age)) %>% 
  mutate(age_bin = 5 * (age %/% 5),
         age_bin = factor(age_bin)) %>%
  ggplot(aes(age_bin, avg_gift_amount, fill = gender)) +
  geom_boxplot() +
  coord_cartesian(ylim = c(0, 250)) +
  labs(title = "Males appear to donate larger amounts and have a wider spread than females",
       subtitle = "Note that this graph only shows supporters whose ages are known",
       x = "Age",
       y = "Average donation amount",
       fill = "Gender",
       caption = "FIGURE 2: Boxplot of average donation amount by age and gender") +
  theme(legend.position = "top")

contacts %>% 
  filter(total_gifts > 0) %>% 
  ggplot(aes(age, avg_gift_amount, color = gender)) +
  geom_point(position = "jitter", alpha = 0.2) +
  scale_y_log10(labels = dollar) +
  geom_smooth() +
  labs(title = "Average donation amount rises with age and declines slightly",
       subtitle = "Beware: the line only looks flat because the y-axis is log-transformed!",
       x = "Age",
       y = "Average donation amount",
       fill = "Gender",
       caption = "FIGURE 3: Scatterplot of average donation amount by age and gender") +
  theme(legend.position = "top")
```

To dig a bit further into this, I took `age`, log-transformed `avg_gift amount` and `num_gifts_last_365_days` and then did a pairwise correlation between them all. The values below are the correlation coefficients. The value 0.56 suggests that there is a moderately strong relationship between age and gift amount. 

```{r}
contacts %>% 
  select(age, avg_gift_amount, num_gifts_last_365_days) %>% 
  mutate(avg_gift_amount = log10(avg_gift_amount + 0.1),
         num_gifts_last_365_days = log10(num_gifts_last_365_days + 0.1)) %>% 
  filter(!is.na(age)) %>% 
  corrr::correlate() %>% 
  corrr::fashion()
```

```{r}
contacts %>% 
  ggplot(aes(age, fill = gender)) +
  geom_histogram(binwidth = 2, color = "grey", position = "fill") +
  labs(title = "More females donate across all age groups than males",
       subtitle = "Do younger donors not like to disclose their gender?",
       x = "Age",
       y = "Proportion of supporters",
       fill = "Gender") +
  scale_y_continuous(labels = percent) +
  theme(legend.position = "top")

contacts %>% 
  ggplot(aes(age, fill = religion)) +
  geom_histogram(binwidth = 2, color = "grey") +
  labs(title = "Most older donors identify as Christian",
       subtitle = "Do younger donors not like to disclose their religion?",
       x = "Age",
       y = "Number of supporters",
       fill = "Religion") +
  theme(legend.position = "top")

contacts %>% 
  filter(!is.na(state)) %>% 
  filter(country == "Australia") %>%
  count(state) %>%
  mutate(state = fct_reorder(state, n)) %>% 
  ggplot(aes(state, n)) +
  geom_col(width = 0.6) +
  coord_flip() +
  labs(title = "Most donors in AUS come from VIC and NSW as expected",
       x = "State",
       y = "Number of supporters")
```

```{r}


contacts %>% 
  select(age, total_gifts) %>%
  mutate(total_gifts = log10(total_gifts + 0.1)) %>% 
  na.omit() %>% 
  corrr::correlate() %>% 
  corrr::fashion()
```


```{r}
campaigns_summarised <- transactions %>%
  mutate(source = str_replace_all(source, "-", " "),
         source = str_replace_all(source, "[0-9]", " ")) %>% 
  unnest_tokens(campaign, source, to_lower = FALSE) %>% 
  left_join(campaign_list, by = "campaign") %>% 
  mutate(campaign = if_else(!is.na(desc), paste0(campaign, " (", desc, ")"), campaign)) %>% 
  group_by(campaign) %>% 
  summarise(n = n(),
            min_amount = min(amount),
            max_amount = max(amount),
            median_amount = median(amount),
            avg_amount = mean(amount),
            total_amount = sum(amount)) %>% 
  arrange(desc(n))

campaigns_summarised %>%
  mutate(campaign = fct_reorder(campaign, n)) %>% 
  head(20) %>% 
  ggplot(aes(n, campaign)) +
  geom_col()

campaigns_summarised %>%
  mutate(campaign = fct_reorder(campaign, total_amount)) %>% 
  head(20) %>% 
  ggplot(aes(total_amount, campaign)) +
  geom_col()

campaigns_summarised %>%
  mutate(campaign = fct_reorder(campaign, median_amount)) %>% 
  head(20) %>% 
  ggplot(aes(median_amount, campaign)) +
  geom_col()

campaigns_summarised %>%
  mutate(campaign = fct_reorder(campaign, max_amount)) %>% 
  head(20) %>% 
  ggplot(aes(max_amount, campaign)) +
  geom_col()
```

```{r}
aus_map_data <- map_data("world") %>% 
  as_tibble() %>% 
  filter(region == "Australia") %>% 
  filter(long < 155)

contacts %>% 
  filter(country == "Australia") %>% 
  filter(lon > 112) %>%
  ggplot(aes(lon, lat)) +
  geom_polygon(aes(long, lat, group = group), data = aus_map_data, fill = "white", color = "grey") +
  geom_point(aes(color = state, size = avg_gift_amount), alpha = 0.2) +
  theme_map()
```













